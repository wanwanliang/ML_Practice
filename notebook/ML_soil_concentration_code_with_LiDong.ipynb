{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#import-packages\" data-toc-modified-id=\"import-packages-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>import packages</a></span></li><li><span><a href=\"#set-work-direcctory-and-read-data\" data-toc-modified-id=\"set-work-direcctory-and-read-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>set work direcctory and read data</a></span><ul class=\"toc-item\"><li><span><a href=\"#preprocessing-data----standardize-data\" data-toc-modified-id=\"preprocessing-data----standardize-data-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>preprocessing data -- standardize data</a></span></li></ul></li><li><span><a href=\"#Run-all-models-100-times-to-get-training-and-testing-accuracy,-and-prediction\" data-toc-modified-id=\"Run-all-models-100-times-to-get-training-and-testing-accuracy,-and-prediction-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Run all models 100 times to get training and testing accuracy, and prediction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-dataframe-to-save-data-and-&amp;-Train-and-test-model\" data-toc-modified-id=\"Create-dataframe-to-save-data-and-&amp;-Train-and-test-model-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Create dataframe to save data and &amp; Train and test model</a></span></li><li><span><a href=\"#write-training-and-testing-accuracy\" data-toc-modified-id=\"write-training-and-testing-accuracy-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>write training and testing accuracy</a></span></li><li><span><a href=\"#write-predictions-from-each-run\" data-toc-modified-id=\"write-predictions-from-each-run-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>write predictions from each run</a></span></li></ul></li><li><span><a href=\"#Get-accuracy\" data-toc-modified-id=\"Get-accuracy-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Get accuracy</a></span><ul class=\"toc-item\"><li><span><a href=\"#Get-mean-and-sd-of-testing-accuracy\" data-toc-modified-id=\"Get-mean-and-sd-of-testing-accuracy-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Get mean and sd of testing accuracy</a></span><ul class=\"toc-item\"><li><span><a href=\"#R2\" data-toc-modified-id=\"R2-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>R2</a></span></li><li><span><a href=\"#MSE\" data-toc-modified-id=\"MSE-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>MSE</a></span></li></ul></li><li><span><a href=\"#Get-mean-and-sd-of-training-accuracy\" data-toc-modified-id=\"Get-mean-and-sd-of-training-accuracy-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Get mean and sd of training accuracy</a></span><ul class=\"toc-item\"><li><span><a href=\"#R2\" data-toc-modified-id=\"R2-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>R2</a></span></li><li><span><a href=\"#MSE\" data-toc-modified-id=\"MSE-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>MSE</a></span></li></ul></li></ul></li><li><span><a href=\"#get-mean-of-predictions-over-100-runs\" data-toc-modified-id=\"get-mean-of-predictions-over-100-runs-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>get mean of predictions over 100 runs</a></span><ul class=\"toc-item\"><li><span><a href=\"#Read-prediction-data\" data-toc-modified-id=\"Read-prediction-data-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Read prediction data</a></span></li><li><span><a href=\"#Get-mean-of-100-prediction\" data-toc-modified-id=\"Get-mean-of-100-prediction-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Get mean of 100 prediction</a></span></li><li><span><a href=\"#Plot-with-median-of-prediction-and-original-observation\" data-toc-modified-id=\"Plot-with-median-of-prediction-and-original-observation-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Plot with median of prediction and original observation</a></span></li></ul></li><li><span><a href=\"#Get-mean-of-variable-importance-or-variable-coefficent-over-100-runs-for-tree-based-models\" data-toc-modified-id=\"Get-mean-of-variable-importance-or-variable-coefficent-over-100-runs-for-tree-based-models-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Get mean of variable importance or variable coefficent over 100 runs for tree-based models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Read-data\" data-toc-modified-id=\"Read-data-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Read data</a></span></li><li><span><a href=\"#Get-mean\" data-toc-modified-id=\"Get-mean-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Get mean</a></span></li></ul></li><li><span><a href=\"#Accuracy-by-land-cover\" data-toc-modified-id=\"Accuracy-by-land-cover-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Accuracy by land cover</a></span></li><li><span><a href=\"#Accuracy-by-depth\" data-toc-modified-id=\"Accuracy-by-depth-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Accuracy by depth</a></span></li><li><span><a href=\"#Parameter-fine-tune:-gradient-search\" data-toc-modified-id=\"Parameter-fine-tune:-gradient-search-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Parameter fine tune: gradient search</a></span></li><li><span><a href=\"#Another-way-to-fine-tune-paramters\" data-toc-modified-id=\"Another-way-to-fine-tune-paramters-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Another way to fine tune paramters</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import GradientBoostingRegressor \n",
    "from lightgbm import LGBMRegressor\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set work direcctory and read data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\s1052014\\\\OneDrive - Syngenta\\\\Desktop\\\\soil')\n",
    "concentration = pd.read_csv('concentration.csv')\n",
    "#concentration = concentration.loc[concentration['Depth']>30]\n",
    "print(concentration.shape)\n",
    "concentration.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing data -- standardize data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_x, dt_y = concentration.drop([\"SOCconcen\"], axis=1),  concentration['SOCconcen']\n",
    "dt_x['Vegetation'].loc[dt_x['Vegetation']==1] = 'grass'\n",
    "dt_x['Vegetation'].loc[dt_x['Vegetation']==2] = 'pine'\n",
    "dt_x['Vegetation'].loc[dt_x['Vegetation']==3] = 'cedar'\n",
    "\n",
    "dt_x['Depth2'] = 0\n",
    "dt_x['Depth2'].loc[dt_x['Depth']<=30] = 1\n",
    "dt_x['Depth2'].loc[(dt_x['Depth']>30)&(dt_x['Depth']<=170)] = 2\n",
    "dt_x['Depth2'].loc[dt_x['Depth']>170] = 3\n",
    "\n",
    "# dt_x['Depth2'].loc[dt_x['Depth']<=10] = 1\n",
    "# dt_x['Depth2'].loc[(dt_x['Depth']>10)&(dt_x['Depth']<=30)] = 2\n",
    "# dt_x['Depth2'].loc[(dt_x['Depth']>30)&(dt_x['Depth']<=100)] = 3\n",
    "# dt_x['Depth2'].loc[(dt_x['Depth']>100)&(dt_x['Depth']<=170)] = 4\n",
    "# dt_x['Depth2'].loc[(dt_x['Depth']>170)&(dt_x['Depth']<=210)] = 5\n",
    "# dt_x['Depth2'].loc[(dt_x['Depth']>210)&(dt_x['Depth']<=300)] = 6\n",
    "\n",
    "dt_x['Category'] = dt_x['Vegetation'] + \"_\" + dt_x['Depth2'].astype(str)\n",
    "dt_x.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_x['Depth2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_x['Vegetation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_x2 = dt_x.drop(['Depth2','Category'],axis=1)\n",
    "dt_x2 = pd.get_dummies(dt_x2)\n",
    "x_nms = dt_x2.columns\n",
    "X = pd.DataFrame(MinMaxScaler().fit_transform(dt_x2))\n",
    "X.columns = x_nms\n",
    "y = dt_y.copy()\n",
    "\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_x2.to_csv('Data_before_standardlization.csv',index=False)\n",
    "X.to_csv('Data_after_standardlization.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run all models 100 times to get training and testing accuracy, and prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe to save data and & Train and test model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df_r2 = pd.DataFrame()\n",
    "ts_df_r2 = pd.DataFrame()\n",
    "tr_df_mse = pd.DataFrame()\n",
    "ts_df_mse = pd.DataFrame()\n",
    "\n",
    "pred_li_df = pd.DataFrame()\n",
    "pred_lasso_df = pd.DataFrame()\n",
    "pred_rf_df = pd.DataFrame()\n",
    "pred_svm_df = pd.DataFrame()\n",
    "pred_xgbr_df = pd.DataFrame()\n",
    "pred_mlp_df = pd.DataFrame()\n",
    "pred_gbr_df = pd.DataFrame()\n",
    "pred_lgbm_df = pd.DataFrame()\n",
    "\n",
    "rf_var_imp_df = pd.DataFrame()\n",
    "gbr_var_imp_df = pd.DataFrame()\n",
    "xgbr_var_imp_df = pd.DataFrame()\n",
    "lgbm_var_imp_df = pd.DataFrame()\n",
    "lasso_coef_df = pd.DataFrame()\n",
    "linear_coef_df = pd.DataFrame()\n",
    "svm_coef_df = pd.DataFrame()\n",
    "\n",
    "for i in range(100):\n",
    "    print(i)\n",
    "    \n",
    "    #X_train, X_test, y_train, y_test = train_test_split(dt_x, dt_y, test_size=0.2, random_state=i*600+23, stratify= ['Vegetation','Depth'])   \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i*600+23, stratify= dt_x['Category'])   \n",
    "    \n",
    "    ## linear model \n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(X_train, y_train)\n",
    "    y_pred_train_li = lin_reg.predict(X_train)\n",
    "    y_pred_test_li = lin_reg.predict(X_test)\n",
    "    pred_li = lin_reg.predict(X)\n",
    "    \n",
    "    mse_train_li = np.sqrt(mean_squared_error(y_train.values.ravel(), y_pred_train_li))\n",
    "    r2_train_li = r2_score(y_train.values.ravel(), y_pred_train_li)\n",
    "    \n",
    "   \n",
    "    mse_test_li =  np.sqrt(mean_squared_error(y_test.values.ravel(), y_pred_test_li))\n",
    "    r2_test_li = r2_score(y_test.values.ravel(), y_pred_test_li)\n",
    "    \n",
    "    r2_train_li = pearsonr(y_train.values.ravel(), y_pred_train_li)[0]\n",
    "    r2_test_li = pearsonr(y_test.values.ravel(), y_pred_test_li)[0]\n",
    "   \n",
    "    index = list(X_test.index)\n",
    "    y_test_df = pd.DataFrame(y_test)\n",
    "    cate_df = pd.DataFrame(dt_x.iloc[index,]['Category'])\n",
    "    y_pred_test_li_df = pd.DataFrame(y_pred_test_li)\n",
    "    y_test_df.index = cate_df.index = y_pred_test_li_df.index = range(y_test_df.shape[0])\n",
    "    all_test_df = pd.concat([y_test_df, cate_df, y_pred_test_li_df], axis=1,ignore_index=True)    \n",
    "    all_test_df.columns = ['Observed', 'Category', 'Linear']\n",
    "    \n",
    "    \n",
    "    ## linear model: lasso \n",
    "    lasso_reg = Lasso(alpha= 0.1)\n",
    "    lasso_reg.fit(X_train, y_train)\n",
    "    y_pred_train_lasso = lasso_reg.predict(X_train)\n",
    "    y_pred_test_lasso = lasso_reg.predict(X_test)\n",
    "    pred_lasso = lasso_reg.predict(X)\n",
    "    \n",
    "   \n",
    "    mse_train_lasso =  np.sqrt(mean_squared_error(y_train.values.ravel(), y_pred_train_lasso))\n",
    "    r2_train_lasso = r2_score(y_train.values.ravel(), y_pred_train_lasso)\n",
    "    \n",
    "\n",
    "    mse_test_lasso =  np.sqrt(mean_squared_error(y_test.values.ravel(), y_pred_test_lasso))\n",
    "    r2_test_lasso = r2_score(y_test.values.ravel(), y_pred_test_lasso)\n",
    "    \n",
    "    r2_train_lasso = pearsonr(y_train.values.ravel(), y_pred_train_lasso)[0]\n",
    "    r2_test_lasso = pearsonr(y_test.values.ravel(), y_pred_test_lasso)[0]\n",
    "    \n",
    "    all_test_df['Lasso'] = y_pred_test_lasso\n",
    "    \n",
    "    ## RF model \n",
    "    rf = RandomForestRegressor(n_estimators=100,  min_samples_leaf=2, max_depth=8)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_train_rf = rf.predict(X_train)\n",
    "    y_pred_test_rf = rf.predict(X_test)\n",
    "    pred_rf = rf.predict(X)\n",
    "    \n",
    "\n",
    "    mse_train_rf =  np.sqrt(mean_squared_error(y_train.values.ravel(), y_pred_train_rf))\n",
    "    r2_train_rf = r2_score(y_train.values.ravel(), y_pred_train_rf)\n",
    "    \n",
    "   \n",
    "    mse_test_rf =  np.sqrt(mean_squared_error(y_test.values.ravel(), y_pred_test_rf))\n",
    "    r2_test_rf = r2_score(y_test.values.ravel(), y_pred_test_rf)\n",
    "    \n",
    "    r2_train_rf = pearsonr(y_train.values.ravel(), y_pred_train_rf)[0]\n",
    "    r2_test_rf = pearsonr(y_test.values.ravel(), y_pred_test_rf)[0]\n",
    "    all_test_df['RF'] = y_pred_test_rf\n",
    "    \n",
    "    \n",
    "    ## SVM model \n",
    "    svm_fit = svm.SVR(kernel= 'linear',shrinking=False, C= 0.2, epsilon = 0.4)\n",
    "    svm_fit.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_train_svm = svm_fit.predict(X_train)\n",
    "    y_pred_test_svm = svm_fit.predict(X_test)\n",
    "    pred_svm = svm_fit.predict(X)\n",
    "    \n",
    "\n",
    "    mse_train_svm =  np.sqrt(mean_squared_error(y_train.values.ravel(), y_pred_train_svm))\n",
    "    r2_train_svm = r2_score(y_train.values.ravel(), y_pred_train_svm)\n",
    "    \n",
    "\n",
    "    mse_test_svm =  np.sqrt(mean_squared_error(y_test.values.ravel(), y_pred_test_svm))\n",
    "    r2_test_svm = r2_score(y_test.values.ravel(), y_pred_test_svm)\n",
    "    all_test_df['SVM'] = y_pred_test_svm\n",
    "    \n",
    "    r2_train_svm = pearsonr(y_train.values.ravel(), y_pred_train_svm)[0]\n",
    "    r2_test_svm = pearsonr(y_test.values.ravel(), y_pred_test_svm)[0]\n",
    "    \n",
    "    ## Gradient boosted tree \n",
    "    gbr = GradientBoostingRegressor(learning_rate=0.15, n_estimators=150, min_samples_leaf=4, max_depth=4)\n",
    "    gbr.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_train_gbr = gbr.predict(X_train)\n",
    "    y_pred_test_gbr = gbr.predict(X_test)\n",
    "    pred_gbr = gbr.predict(X)\n",
    "    \n",
    "   \n",
    "    mse_train_gbr =  np.sqrt(mean_squared_error(y_train.values.ravel(), y_pred_train_gbr))\n",
    "    r2_train_gbr = r2_score(y_train.values.ravel(), y_pred_train_gbr)\n",
    "    \n",
    "   \n",
    "    mse_test_gbr =  np.sqrt(mean_squared_error(y_test.values.ravel(), y_pred_test_gbr))\n",
    "    r2_test_gbr = r2_score(y_test.values.ravel(), y_pred_test_gbr)\n",
    "    all_test_df['GBR'] = y_pred_test_gbr\n",
    "    \n",
    "    r2_train_gbr = pearsonr(y_train.values.ravel(), y_pred_train_gbr)[0]\n",
    "    r2_test_gbr = pearsonr(y_test.values.ravel(), y_pred_test_gbr)[0]\n",
    "    \n",
    "    ## Light GBM\n",
    "    lgbm = LGBMRegressor(learning_rate=0.2, min_data_in_leaf= 3, max_depth=4, boosting_type='dart', n_estimators=300)\n",
    "    lgbm.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_train_lgbm = lgbm.predict(X_train)\n",
    "    y_pred_test_lgbm = lgbm.predict(X_test)\n",
    "    pred_lgbm = lgbm.predict(X)\n",
    "    \n",
    "   \n",
    "    mse_train_lgbm =  np.sqrt(mean_squared_error(y_train.values.ravel(), y_pred_train_lgbm))\n",
    "    r2_train_lgbm = r2_score(y_train.values.ravel(), y_pred_train_lgbm)\n",
    "    \n",
    "   \n",
    "    mse_test_lgbm =  np.sqrt(mean_squared_error(y_test.values.ravel(), y_pred_test_lgbm))\n",
    "    r2_test_lgbm = r2_score(y_test.values.ravel(), y_pred_test_lgbm)\n",
    "    all_test_df['LGBM'] = y_pred_test_lgbm\n",
    "    \n",
    "    r2_train_lgbm = pearsonr(y_train.values.ravel(), y_pred_train_lgbm)[0]\n",
    "    r2_test_lgbm = pearsonr(y_test.values.ravel(), y_pred_test_lgbm)[0]\n",
    "    \n",
    "    ## XGBoost\n",
    "    xgbr = xgb.XGBRegressor(learning_rate =0.15, max_depth=6, gamma=5, reg_lambda=0.3, reg_alpha=0.1, min_samples_leaf=2, n_estimators=200)\n",
    "    xgbr.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_train_xgbr = xgbr.predict(X_train)\n",
    "    y_pred_test_xgbr = xgbr.predict(X_test)\n",
    "    pred_xgbr = xgbr.predict(X)\n",
    "    \n",
    " \n",
    "    mse_train_xgbr =  np.sqrt(mean_squared_error(y_train.values.ravel(), y_pred_train_xgbr))\n",
    "    r2_train_xgbr = r2_score(y_train.values.ravel(), y_pred_train_xgbr)\n",
    "    \n",
    "\n",
    "    mse_test_xgbr =  np.sqrt(mean_squared_error(y_test.values.ravel(), y_pred_test_xgbr))\n",
    "    r2_test_xgbr = r2_score(y_test.values.ravel(), y_pred_test_xgbr)\n",
    "    all_test_df['XGBR'] = y_pred_test_xgbr\n",
    "\n",
    "    r2_train_xgbr = pearsonr(y_train.values.ravel(), y_pred_train_xgbr)[0]\n",
    "    r2_test_xgbr = pearsonr(y_test.values.ravel(), y_pred_test_xgbr)[0]\n",
    "    \n",
    "    ## MLP\n",
    "    MLP_model = Sequential()\n",
    "    MLP_model.add(Dense(20, activation='relu', name='layer1', input_dim = dt_x.shape[1]))\n",
    "    MLP_model.add(Dense(20, activation='relu', name='layer2'))\n",
    "    MLP_model.add(Dense(1, name='layer4'))\n",
    "    MLP_model.compile(optimizer= keras.optimizers.Adam(lr=0.001), loss='mse')\n",
    "    MLP_model.fit(X_train, y_train, epochs=500, batch_size=2,verbose=0)\n",
    "\n",
    "    y_pred_train_mlpm =  MLP_model.predict(X_train)\n",
    "    y_pred_test_mlpm =  MLP_model.predict(X_test)\n",
    "    pred_mlp = MLP_model.predict(X)\n",
    "\n",
    "   \n",
    "    mse_train_mlpm = np.sqrt( mean_squared_error(y_train.values.ravel(), y_pred_train_mlpm))\n",
    "    r2_train_mlpm = r2_score(y_train.values.ravel(), y_pred_train_mlpm)\n",
    "\n",
    "  \n",
    "    mse_test_mlpm = np.sqrt( mean_squared_error(y_test.values.ravel(), y_pred_test_mlpm))\n",
    "    r2_test_mlpm = r2_score(y_test.values.ravel(), y_pred_test_mlpm)\n",
    "    all_test_df['MLP'] = y_pred_test_mlpm\n",
    "    \n",
    "    r2_train_mlpm = pearsonr(y_train.values.ravel(), y_pred_train_mlpm.ravel())[0]\n",
    "    r2_test_mlpm = pearsonr(y_test.values.ravel(), y_pred_test_mlpm.ravel())[0]\n",
    "    \n",
    "    nmA = 'Test_pred_all_run' + str(i) +'.csv'\n",
    "    all_test_df.to_csv(nmA)\n",
    "    \n",
    "    ## save training and testing metrics ##\n",
    "    mse_tr = [mse_train_li,mse_train_lasso, mse_train_svm,mse_train_rf, mse_train_xgbr,  mse_train_gbr, mse_train_lgbm, mse_train_mlpm]\n",
    "    mse_ts = [mse_test_li, mse_test_lasso,  mse_test_svm,mse_test_rf,mse_test_xgbr,  mse_test_gbr, mse_test_lgbm, mse_test_mlpm]\n",
    "    r2_tr = [r2_train_li, r2_train_lasso,r2_train_svm,  r2_train_rf, r2_train_xgbr, r2_train_gbr, r2_train_lgbm, r2_train_mlpm]\n",
    "    r2_ts = [r2_test_li, r2_test_lasso,r2_test_svm, r2_test_rf, r2_test_xgbr,  r2_test_gbr, r2_test_lgbm, r2_test_mlpm]\n",
    "    r2_tr = pd.DataFrame(r2_tr)\n",
    "    r2_ts = pd.DataFrame(r2_ts)\n",
    "    mse_tr = pd.DataFrame(mse_tr)\n",
    "    mse_ts = pd.DataFrame(mse_ts)\n",
    "    ts_df_r2 = pd.concat([ts_df_r2, r2_ts], axis=1)\n",
    "    tr_df_r2 = pd.concat([tr_df_r2, r2_tr], axis=1)\n",
    "    ts_df_mse = pd.concat([ts_df_mse, mse_ts], axis=1)\n",
    "    tr_df_mse = pd.concat([tr_df_mse, mse_tr], axis=1)\n",
    "    \n",
    "    ## save training and testing predictions ##\n",
    "    pred_li_df = pd.concat([pred_li_df, pd.DataFrame(pred_li)], axis=1)\n",
    "    pred_lasso_df = pd.concat([pred_lasso_df, pd.DataFrame(pred_lasso)], axis=1)\n",
    "    pred_xgbr_df = pd.concat([pred_xgbr_df, pd.DataFrame(pred_xgbr)], axis=1)\n",
    "    pred_svm_df = pd.concat([pred_svm_df, pd.DataFrame(pred_svm)], axis=1)\n",
    "    pred_mlp_df = pd.concat([pred_mlp_df, pd.DataFrame(pred_mlp)], axis=1)\n",
    "    pred_rf_df = pd.concat([pred_rf_df, pd.DataFrame(pred_rf)], axis=1)\n",
    "    pred_lgbm_df = pd.concat([pred_lgbm_df, pd.DataFrame(pred_lgbm)], axis=1)\n",
    "    pred_gbr_df = pd.concat([pred_gbr_df, pd.DataFrame(pred_gbr)], axis=1)\n",
    "    \n",
    "    ## save tree-based model variable importance \n",
    "    rf_var_imp_df = pd.concat([rf_var_imp_df, pd.DataFrame(rf.feature_importances_)], axis=1)\n",
    "    gbr_var_imp_df = pd.concat([gbr_var_imp_df, pd.DataFrame(gbr.feature_importances_)], axis=1)\n",
    "    xgbr_var_imp_df = pd.concat([xgbr_var_imp_df, pd.DataFrame(xgbr.feature_importances_)], axis=1)\n",
    "    lgbm_var_imp_df = pd.concat([lgbm_var_imp_df, pd.DataFrame(lgbm.feature_importances_)], axis=1)\n",
    "   \n",
    "    ## save linear model coefficients\n",
    "    lasso_coef_df = pd.concat([lasso_coef_df, pd.DataFrame(lasso_reg.coef_)], axis=1)\n",
    "    linear_coef_df = pd.concat([linear_coef_df, pd.DataFrame(lin_reg.coef_)], axis=1)\n",
    "    svm_coef_df = pd.concat([svm_coef_df, pd.DataFrame(svm_fit.coef_).T], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write training and testing accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nms = ['Linear','Lasso','SVM','RF', 'XGBR','GBR','LGBM','MLP']\n",
    "ts_df_r2b = ts_df_r2.T\n",
    "tr_df_r2b = tr_df_r2.T\n",
    "ts_df_mseb = ts_df_mse.T\n",
    "tr_df_mseb = tr_df_mse.T\n",
    "\n",
    "ts_df_r2b.columns = tr_df_r2b.columns = ts_df_mseb.columns = tr_df_mseb.columns= nms\n",
    "ts_df_r2b.to_csv('testing_r2.csv', index=False)\n",
    "tr_df_r2b.to_csv('training_r2.csv', index=False)\n",
    "tr_df_mseb.to_csv('training_mse.csv', index=False)\n",
    "ts_df_mseb.to_csv('testing_mse.csv', index=False)\n",
    "\n",
    "rf_var_imp_df2 = pd.DataFrame(rf_var_imp_df.T)\n",
    "gbr_var_imp_df2 = pd.DataFrame(gbr_var_imp_df.T)\n",
    "lgbm_var_imp_df2 = pd.DataFrame(lgbm_var_imp_df.T)\n",
    "xgbr_var_imp_df2 = pd.DataFrame(xgbr_var_imp_df.T)\n",
    "\n",
    "lasso_coef_df2 = pd.DataFrame(lasso_coef_df.T)\n",
    "linear_coef_df2 = pd.DataFrame(linear_coef_df.T)\n",
    "svm_coef_df2 = pd.DataFrame(svm_coef_df.T)\n",
    "\n",
    "\n",
    "rf_var_imp_df2.columns = gbr_var_imp_df2.columns = lgbm_var_imp_df2.columns = xgbr_var_imp_df2.columns = lasso_coef_df2.columns = linear_coef_df2.columns = svm_coef_df2.columns =x_nms\n",
    "rf_var_imp_df2.to_csv('RF_var_imp.csv', index=False)\n",
    "gbr_var_imp_df2.to_csv('GBR_var_imp.csv', index=False)\n",
    "lgbm_var_imp_df2.to_csv('LGBR_var_imp.csv', index=False)\n",
    "xgbr_var_imp_df2.to_csv('XGBR_var_imp.csv', index=False)\n",
    "lasso_coef_df2.to_csv('Lasso_var_coefficient.csv', index=False)\n",
    "linear_coef_df2.to_csv('Linear_var_coefficient.csv', index=False)\n",
    "svm_coef_df2.to_csv('SVM_var_coefficient.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write predictions from each run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mlp_df.to_csv('MLP_pred.csv', index=False)\n",
    "pred_li_df.to_csv('Linear_pred.csv',index=False)\n",
    "pred_lasso_df.to_csv('Lasso_pred.csv',index=False)\n",
    "pred_svm_df.to_csv('SVM_pred.csv',index=False)\n",
    "pred_gbr_df.to_csv('GBR_pred.csv',index=False)\n",
    "pred_lgbm_df.to_csv('LGBR_pred.csv',index=False)\n",
    "pred_rf_df.to_csv('Random_Forest_pred.csv',index=False)\n",
    "pred_xgbr_df.to_csv('XGBR_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get mean and sd of testing accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('./results/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_r2 = pd.read_csv('cedar_test_r2.csv')\n",
    "ts_r2.mean(axis=0).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_r2 = pd.read_csv('grass_test_r2.csv')\n",
    "ts_r2.mean(axis=0).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_r2 = pd.read_csv('pine_test_r2.csv')\n",
    "ts_r2.mean(axis=0).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_r2.std(axis=0).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_r2.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_mse = pd.read_csv('testing_mse.csv')\n",
    "ts_mse.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_mse.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get mean and sd of training accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_r2 = pd.read_csv('training_r2.csv')\n",
    "tr_r2.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_r2.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MSE  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_mse = pd.read_csv('training_mse.csv')\n",
    "tr_mse.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_mse.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get mean of predictions over 100 runs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read prediction data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mlp_df = pd.read_csv('MLP_pred.csv')\n",
    "pred_li_df = pd.read_csv('Linear_pred.csv')\n",
    "pred_lasso_df = pd.read_csv('Lasso_pred.csv')\n",
    "pred_svm_df = pd.read_csv('SVM_pred.csv')\n",
    "pred_gbr_df = pd.read_csv('GBR_pred.csv')\n",
    "pred_xgbr_df = pd.read_csv('XGBR_pred.csv')\n",
    "pred_lgbm_df = pd.read_csv('LGBR_pred.csv')\n",
    "pred_rf_df = pd.read_csv('Random_Forest_pred.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get mean of 100 prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mlp_mean = pred_mlp_df.mean(axis=1)\n",
    "pred_li_mean = pred_li_df.mean(axis=1)\n",
    "pred_lasso_mean = pred_lasso_df.mean(axis=1)\n",
    "pred_rf_mean = pred_rf_df.mean(axis=1)\n",
    "pred_svm_mean = pred_svm_df.mean(axis=1)\n",
    "pred_gbr_mean = pred_gbr_df.mean(axis=1)\n",
    "pred_xgbr_mean = pred_xgbr_df.mean(axis=1)\n",
    "pred_lgbm_mean = pred_lgbm_df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Plot with median of prediction and original observation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(pred_lasso_mean, dt_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get mean of variable importance or variable coefficent over 100 runs for tree-based models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_var_imp_df= pd.read_csv('RF_var_imp.csv')\n",
    "gbr_var_imp_df= pd.read_csv('GBR_var_imp.csv')\n",
    "lgbr_var_imp_df= pd.read_csv('LGBR_var_imp.csv')\n",
    "xgbr_var_imp_df = pd.read_csv('XGBR_var_imp.csv')\n",
    "\n",
    "lasso_var_coef_df = pd.read_csv('Lasso_var_coefficient.csv')\n",
    "linear_var_coef_df = pd.read_csv('Linear_var_coefficient.csv')\n",
    "svm_var_coef_df = pd.read_csv('SVM_var_coefficient.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_var_imp = rf_var_imp_df.mean(axis=0)\n",
    "gbr_var_imp = gbr_var_imp_df.mean(axis=0)\n",
    "lgbr_var_imp = lgbr_var_imp_df.mean(axis=0)\n",
    "xgbr_var_imp = xgbr_var_imp_df.mean(axis=0)\n",
    "lasso_var_coef = lasso_var_coef_df.mean(axis=0)\n",
    "linear_var_coef = linear_var_coef_df.mean(axis=0)\n",
    "svm_var_coef = svm_var_coef_df.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_var_coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy by land cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lc(string):\n",
    "    ts = string.split('_')\n",
    "    lc = ts[0]\n",
    "    depth = ts[1]\n",
    "    return lc\n",
    "def depth(string):\n",
    "    ts = string.split('_')\n",
    "    lc = ts[0]\n",
    "    depth = ts[1]\n",
    "    return depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grass_df_r2 = pd.DataFrame()\n",
    "pine_df_r2 = pd.DataFrame()\n",
    "cedar_df_r2 = pd.DataFrame()\n",
    "\n",
    "grass_df_mse = pd.DataFrame()\n",
    "pine_df_mse = pd.DataFrame()\n",
    "cedar_df_mse = pd.DataFrame()\n",
    "\n",
    "ldtps = ['grass', 'pine', 'cedar']\n",
    "for i in range(100):\n",
    "    fl_nm = 'Test_pred_all_run' + str(i) +'.csv'\n",
    "    ac = pd.read_csv(fl_nm)\n",
    "    ac['land_type']= ac['Category'].map(lc)\n",
    "    ac['depth']= ac['Category'].map(depth)\n",
    "\n",
    "    for ldtp in ldtps:\n",
    "        ac_sm = ac.loc[ac['land_type']==ldtp]\n",
    "\n",
    "        mse_li =  np.sqrt(mean_squared_error(ac_sm['Observed'],ac_sm['Linear'] ))\n",
    "        r2_li = pearsonr(ac_sm['Observed'],ac_sm['Linear'])[0]\n",
    "        #r2_li = r2_score(ac_sm['Observed'],ac_sm['Linear'])\n",
    "        \n",
    "        mse_lasso =  np.sqrt(mean_squared_error(ac_sm['Observed'],ac_sm['Lasso'] ))\n",
    "        r2_lasso = pearsonr(ac_sm['Observed'],ac_sm['Lasso'])[0]\n",
    "        #r2_lasso = r2_score(ac_sm['Observed'],ac_sm['Lasso'])\n",
    "        \n",
    "        mse_rf =  np.sqrt(mean_squared_error(ac_sm['Observed'],ac_sm['RF'] ))\n",
    "        r2_rf = pearsonr(ac_sm['Observed'],ac_sm['RF'])[0]\n",
    "        #r2_rf = r2_score(ac_sm['Observed'],ac_sm['RF'])\n",
    "        \n",
    "        mse_svm =  np.sqrt(mean_squared_error(ac_sm['Observed'],ac_sm['SVM'] ))\n",
    "        r2_svm = pearsonr(ac_sm['Observed'],ac_sm['SVM'])[0]\n",
    "       # r2_svm = r2_score(ac_sm['Observed'],ac_sm['SVM'])\n",
    "        \n",
    "        mse_gbr =  np.sqrt(mean_squared_error(ac_sm['Observed'],ac_sm['GBR'] ))\n",
    "        r2_gbr = pearsonr(ac_sm['Observed'],ac_sm['GBR'])[0]\n",
    "       # r2_gbr = r2_score(ac_sm['Observed'],ac_sm['GBR'])\n",
    "        \n",
    "        mse_lgbm =  np.sqrt(mean_squared_error(ac_sm['Observed'],ac_sm['LGBM'] ))\n",
    "        r2_lgbm = pearsonr(ac_sm['Observed'],ac_sm['LGBM'])[0]\n",
    "       # r2_lgbm = r2_score(ac_sm['Observed'],ac_sm['LGBM'])\n",
    "        \n",
    "        mse_xgbr =  np.sqrt(mean_squared_error(ac_sm['Observed'],ac_sm['XGBR'] ))\n",
    "        r2_xgbr = pearsonr(ac_sm['Observed'],ac_sm['XGBR'])[0]\n",
    "       # r2_xgbr = r2_score(ac_sm['Observed'],ac_sm['XGBR'])\n",
    "        \n",
    "        mse_mlp =  np.sqrt(mean_squared_error(ac_sm['Observed'],ac_sm['MLP'] ))\n",
    "        r2_mlp = pearsonr(ac_sm['Observed'],ac_sm['MLP'])[0]\n",
    "       # r2_mlp = r2_score(ac_sm['Observed'],ac_sm['MLP'])\n",
    "\n",
    "        mses = [mse_li, mse_lasso,  mse_svm, mse_rf,mse_gbr, mse_lgbm, mse_xgbr, mse_mlp]\n",
    "        r2s = [r2_li, r2_lasso,  r2_svm, r2_rf,r2_gbr, r2_lgbm, r2_xgbr, r2_mlp]\n",
    "        mses_df = pd.DataFrame(mses).T\n",
    "        r2s_df = pd.DataFrame(r2s).T\n",
    "\n",
    "        if ldtp=='grass':\n",
    "            grass_df_r2 = pd.concat([grass_df_r2, r2s_df], axis=0)\n",
    "            grass_df_mse = pd.concat([grass_df_mse, mses_df], axis=0)\n",
    "        elif ldtp=='pine':\n",
    "            pine_df_r2 = pd.concat([pine_df_r2, r2s_df], axis=0)\n",
    "            pine_df_mse = pd.concat([pine_df_mse, mses_df], axis=0)\n",
    "        else:\n",
    "            cedar_df_r2 = pd.concat([cedar_df_r2, r2s_df], axis=0)\n",
    "            cedar_df_mse = pd.concat([cedar_df_mse, mses_df], axis=0)\n",
    "        \n",
    "cedar_df_r2.columns = cedar_df_mse.columns = grass_df_r2.columns = grass_df_mse.columns = pine_df_r2.columns = pine_df_mse.columns = ['Linear','Lasso','SVM','RF','GBR','LGBM','XGBR','MLP']\n",
    "cedar_df_r2 = cedar_df_r2.pow(2)\n",
    "grass_df_r2 = grass_df_r2.pow(2)\n",
    "pine_df_r2 = pine_df_r2.pow(2)\n",
    "cedar_df_r2.to_csv('cedar_test_r2.csv', index=False)\n",
    "grass_df_r2.to_csv('grass_test_r2.csv', index=False)\n",
    "pine_df_r2.to_csv('pine_test_r2.csv', index=False)\n",
    "cedar_df_mse.to_csv('cedar_test_mse.csv', index=False)\n",
    "grass_df_mse.to_csv('grass_test_mse.csv', index=False)\n",
    "pine_df_mse.to_csv('pine_test_mse.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy by depth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_df_r2 = pd.DataFrame()\n",
    "d2_df_r2 = pd.DataFrame()\n",
    "d3_df_r2 = pd.DataFrame()\n",
    "d4_df_r2 = pd.DataFrame()\n",
    "d5_df_r2 = pd.DataFrame()\n",
    "d6_df_r2 = pd.DataFrame()\n",
    "\n",
    "d1_df_mse = pd.DataFrame()\n",
    "d2_df_mse = pd.DataFrame()\n",
    "d3_df_mse = pd.DataFrame()\n",
    "d4_df_mse = pd.DataFrame()\n",
    "d5_df_mse = pd.DataFrame()\n",
    "d6_df_mse = pd.DataFrame()\n",
    "\n",
    "\n",
    "#dpts = ['1','2','3','4','5','6']\n",
    "dpts = ['1','2','3']\n",
    "for i in range(100):\n",
    "    fl_nm = 'Test_pred_all_run' + str(i) +'.csv'\n",
    "    ac = pd.read_csv(fl_nm)\n",
    "    ac['land_type']= ac['Category'].map(lc)\n",
    "    ac['depth']= ac['Category'].map(depth)\n",
    "\n",
    "    for dp in dpts:\n",
    "        ac_sm = ac.loc[ac['depth']==dp]\n",
    "\n",
    "        mse_li =  np.sqrt(mean_squared_error(ac_sm['Observed'],ac_sm['Linear'] ))\n",
    "        r2_li = pearsonr(ac_sm['Observed'],ac_sm['Linear'])[0]\n",
    "        #r2_li = r2_score(ac_sm['Observed'],ac_sm['Linear'])\n",
    "        \n",
    "        mse_lasso =  np.sqrt(mean_squared_error(ac_sm['Observed'],ac_sm['Lasso'] ))\n",
    "        r2_lasso = pearsonr(ac_sm['Observed'],ac_sm['Lasso'])[0]\n",
    "        #r2_lasso = r2_score(ac_sm['Observed'],ac_sm['Lasso'])\n",
    "        \n",
    "        mse_rf =  np.sqrt(mean_squared_error(ac_sm['Observed'],ac_sm['RF'] ))\n",
    "        r2_rf = pearsonr(ac_sm['Observed'],ac_sm['RF'])[0]\n",
    "       # r2_rf =r2_score(ac_sm['Observed'],ac_sm['RF'])\n",
    "        \n",
    "        mse_svm =  np.sqrt(mean_squared_error(ac_sm['Observed'],ac_sm['SVM'] ))\n",
    "        r2_svm = pearsonr(ac_sm['Observed'],ac_sm['SVM'])[0]\n",
    "        #r2_svm = r2_score(ac_sm['Observed'],ac_sm['SVM'])\n",
    "        \n",
    "        \n",
    "        mse_gbr =  np.sqrt(mean_squared_error(ac_sm['Observed'],ac_sm['GBR'] ))\n",
    "        r2_gbr = pearsonr(ac_sm['Observed'],ac_sm['GBR'])[0]\n",
    "        #r2_gbr = r2_score(ac_sm['Observed'],ac_sm['GBR'])\n",
    "        \n",
    "        mse_lgbm =  np.sqrt(mean_squared_error(ac_sm['Observed'],ac_sm['LGBM'] ))\n",
    "        r2_lgbm = pearsonr(ac_sm['Observed'],ac_sm['LGBM'])[0]\n",
    "        #r2_lgbm = r2_score(ac_sm['Observed'],ac_sm['LGBM'])\n",
    "        \n",
    "        mse_xgbr =  np.sqrt(mean_squared_error(ac_sm['Observed'],ac_sm['XGBR'] ))\n",
    "        r2_xgbr = pearsonr(ac_sm['Observed'],ac_sm['XGBR'])[0]\n",
    "        #r2_xgbr = r2_score(ac_sm['Observed'],ac_sm['XGBR'])\n",
    "        \n",
    "        mse_mlp =  np.sqrt(mean_squared_error(ac_sm['Observed'],ac_sm['MLP'] ))\n",
    "        r2_mlp = pearsonr(ac_sm['Observed'],ac_sm['MLP'])[0]\n",
    "       # r2_mlp = r2_score(ac_sm['Observed'],ac_sm['MLP'])\n",
    "\n",
    "        mses = [mse_li, mse_lasso,  mse_svm, mse_rf,mse_gbr, mse_lgbm, mse_xgbr, mse_mlp]\n",
    "        r2s = [r2_li, r2_lasso,  r2_svm, r2_rf,r2_gbr, r2_lgbm, r2_xgbr, r2_mlp]\n",
    "        mses_df = pd.DataFrame(mses).T\n",
    "        r2s_df = pd.DataFrame(r2s).T\n",
    "        \n",
    "        if dp=='1':\n",
    "            d1_df_r2 = pd.concat([d1_df_r2, r2s_df], axis=0)\n",
    "            d1_df_mse = pd.concat([d1_df_mse, mses_df], axis=0)\n",
    "        elif dp=='2':\n",
    "            d2_df_r2 = pd.concat([d2_df_r2, r2s_df], axis=0)\n",
    "            d2_df_mse = pd.concat([d2_df_mse, mses_df], axis=0)\n",
    "        elif dp=='3':\n",
    "            d3_df_r2 = pd.concat([d3_df_r2, r2s_df], axis=0)\n",
    "            d3_df_mse = pd.concat([d3_df_mse, mses_df], axis=0)\n",
    "        elif dp=='4':\n",
    "            d4_df_r2 = pd.concat([d4_df_r2, r2s_df], axis=0)\n",
    "            d4_df_mse = pd.concat([d4_df_mse, mses_df], axis=0)\n",
    "        elif dp=='5':\n",
    "            d5_df_r2 = pd.concat([d5_df_r2, r2s_df], axis=0)\n",
    "            d5_df_mse = pd.concat([d5_df_mse, mses_df], axis=0)\n",
    "        elif dp=='6':\n",
    "            d6_df_r2 = pd.concat([d6_df_r2, r2s_df], axis=0)\n",
    "            d6_df_mse = pd.concat([d6_df_mse, mses_df], axis=0)\n",
    "        \n",
    "        \n",
    "#d1_df_r2.columns = d2_df_r2.columns = d3_df_r2.columns = d4_df_r2.columns = d5_df_r2.columns = d6_df_r2.columns =d1_df_mse.columns = d2_df_mse.columns = d3_df_mse.columns = d4_df_mse.columns = d5_df_mse.columns = d6_df_mse.columns =['Linear','Lasso','SVM','RF','GBR','LGBM','XGBR','MLP']\n",
    "d3_df_r2.columns = d4_df_r2.columns = d5_df_r2.columns = d6_df_r2.columns =  d3_df_mse.columns = d4_df_mse.columns = d5_df_mse.columns = d6_df_mse.columns =['Linear','Lasso','SVM','RF','GBR','LGBM','XGBR','MLP']\n",
    "\n",
    "#d1_df_r2 = d1_df_r2.pow(2)\n",
    "#d2_df_r2 = d2_df_r2.pow(2)\n",
    "d3_df_r2 = d3_df_r2.pow(2)\n",
    "d4_df_r2 = d4_df_r2.pow(2)\n",
    "d5_df_r2 = d5_df_r2.pow(2)\n",
    "d6_df_r2 = d6_df_r2.pow(2)\n",
    "#d1_df_r2.to_csv('depth1_test_r2.csv', index=False)\n",
    "#d2_df_r2.to_csv('depth2_test_r2.csv', index=False)\n",
    "d3_df_r2.to_csv('depth3_test_r2.csv', index=False)\n",
    "d4_df_r2.to_csv('depth4_test_r2.csv', index=False)\n",
    "d5_df_r2.to_csv('depth5_test_r2.csv', index=False)\n",
    "d6_df_r2.to_csv('depth6_test_r2.csv', index=False)\n",
    "#d1_df_mse.to_csv('depth1_test_mse.csv', index=False)\n",
    "#d2_df_mse.to_csv('depth2_test_mse.csv', index=False)\n",
    "d3_df_mse.to_csv('depth3_test_mse.csv', index=False)\n",
    "d4_df_mse.to_csv('depth4_test_mse.csv', index=False)\n",
    "d5_df_mse.to_csv('depth5_test_mse.csv', index=False)\n",
    "d6_df_mse.to_csv('depth6_test_mse.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_df_r2.columns = d2_df_r2.columns =d3_df_r2.columns = d1_df_mse.columns = d2_df_mse.columns =d3_df_mse.columns = ['Linear','Lasso','SVM','RF','GBR','LGBM','XGBR','MLP']\n",
    "\n",
    "d1_df_r2 = d1_df_r2.pow(2)\n",
    "d2_df_r2 = d2_df_r2.pow(2)\n",
    "d3_df_r2 = d3_df_r2.pow(2)\n",
    "d1_df_r2.to_csv('depth1_test_r2.csv', index=False)\n",
    "d2_df_r2.to_csv('depth2_test_r2.csv', index=False)\n",
    "d3_df_r2.to_csv('depth3_test_r2.csv', index=False)\n",
    "# d4_df_r2.to_csv('depth4_test_r2.csv', index=False)\n",
    "# d5_df_r2.to_csv('depth5_test_r2.csv', index=False)\n",
    "# d6_df_r2.to_csv('depth6_test_r2.csv', index=False)\n",
    "\n",
    "#d1_df_mse.to_csv('depth1_test_mse.csv', index=False)\n",
    "#d2_df_mse.to_csv('depth2_test_mse.csv', index=False)\n",
    "#d3_df_mse.to_csv('depth3_test_mse.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter fine tune: gradient search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_md(n_layers=2, n_neuron=10, lr=0.001):\n",
    "    MLP_model = Sequential()\n",
    "    MLP_model.add(Dense(n_neuron, activation='relu',  input_dim = dt_x.shape[1]))\n",
    "    \n",
    "    for i in range(n_layers-1):\n",
    "        MLP_model.add(Dense(n_neuron, activation='relu'))\n",
    "    \n",
    "    MLP_model.add(Dense(1))\n",
    "    MLP_model.compile(optimizer= keras.optimizers.Adam(lr=lr), loss='mse')   \n",
    "    return MLP_model     \n",
    "\n",
    "param_grid = dict(lr=[ 0.001,0.005, 0.01], n_neuron=[10,20,50], n_layers=[1,2,3], batch_size=[2,4,8], epochs=[200,300,500])\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "svm = KerasRegressor(build_fn=mlp_md, verbose=0)\n",
    "clf = GridSearchCV(svm, param_grid=param_grid)\n",
    "clf.fit(X, y)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SVM\n",
    "parameters = {'kernel':['linear', 'rbf','polynomial'], 'C':[0.1,0.2,0.3,0.4,0.5,1,2,3,4,5], 'epsilon':[0.1,0.2,0.3,0.4,0.5,1,2,3,4,5]}\n",
    "## Lasso \n",
    "#parameters = {'alpha':[0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5]}\n",
    "## RF\n",
    "#parameters = {'n_estimators':[50,100,150,200,250,300], 'min_samples_leaf':[2,3,4],'max_depth':[4,6,8,10,12,14,16,18]}\n",
    "\n",
    "##XGB\n",
    "parameters = {'learning_rate':[0.05, 0.1,0.15, 0.2],'reg_lambda':[ 0, 3, 5.0, 8, 10.0,15],'gamma': [0, 0.5, 1.0,2,5 ], 'reg_alpha':[0,0.05,0.1,0.2],'n_estimators':[100,200,300],'min_samples_leaf':[2,3,4],'max_depth':[4,6,8]}\n",
    "##  GBR\n",
    "#parameters = {'learning_rate':[0.01,0.05, 0.1,0.15],'n_estimators':[100,200,300,400, 500], 'min_samples_leaf':[2,3,4],'max_depth':[4,6,8,10]}\n",
    "\n",
    "## LGBR\n",
    "#parameters = {'boosting_type':['gbdt', 'dart', 'goss','rf'], 'learning_rate':[ 0.01,0.05, 0.1, 0.2],'n_estimators':[50,100,150,200,250,300], 'min_samples_leaf':[2,3,4],'max_depth':[4,6,8,10,12]}\n",
    "## LGBR\n",
    "#parameters = {'boosting_type':['gbdt', 'dart', 'goss','rf'], 'learning_rate':[ 0.1, 0.2, 0.3],'n_estimators':[100, 200,300, 400], 'min_samples_leaf':[2,3,4],'max_depth':[4,6,8,10]}\n",
    "\n",
    "## MLP\n",
    "#param_grid = dict(lr=[ 0.001,0.005, 0.01], n_neuron=[10,20,50], n_layers=[1,2,3], batch_size=[2,4,8], epochs=[200,300,500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm = svm.SVR()\n",
    "#svm =  GradientBoostingRegressor()\n",
    "svm =  xgb.XGBRegressor()\n",
    "clf = GridSearchCV(svm, parameters)\n",
    "clf.fit(X, y)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another way to fine tune paramters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_df = pd.DataFrame()\n",
    "paras= [1,2,5,10,15]\n",
    "for n in paras:\n",
    "    \n",
    "    rs = []\n",
    "    for i in range(50):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=i*600+23, stratify= dt_x['Category'])\n",
    "        rf = xgb.XGBRegressor(learning_rate =0.15, max_depth=6, gamma=5, reg_lambda=0.3, reg_alpha=0.1, min_samples_leaf=2, n_estimators=200)   \n",
    "        rf.fit(X_train, y_train)\n",
    "    \n",
    "       # rf = RandomForestRegressor(n_estimators=400,  min_samples_leaf=n)\n",
    "        #rf.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_train_gbr = rf.predict(X_train)\n",
    "        y_pred_test_gbr = rf.predict(X_test)\n",
    "        pred_gbr = rf.predict(X)\n",
    "       # r2_test_gbr = r2_score(y_test.values.ravel(), y_pred_test_gbr)\n",
    "        r2_test_gbr =  pearsonr(y_test.values.ravel(), y_pred_test_gbr)[0]\n",
    "        r2_test_gbr = r2_test_gbr*r2_test_gbr \n",
    "        rs.append(r2_test_gbr)\n",
    "    rs = pd.DataFrame(rs)\n",
    "    r2_df = pd.concat([r2_df, rs], axis=1)\n",
    "    \n",
    "r2_df.columns = paras\n",
    "r2_df.describe().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.091px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
